[package]
name = "candle-video"
version = "0.1.0"
edition = "2024"
authors = ["FerrisMind"]
description = "LTX-Video integration for Candle framework"
license = "Apache-2.0"
repository = "https://github.com/FerrisMind/candle-video"

[lib]
name = "candle_video"
path = "src/lib.rs"

[dependencies]
candle-core = { git = "https://github.com/huggingface/candle.git", tag = "0.9.2-alpha.2", features = ["cuda", "cudnn"] }
candle-nn = { git = "https://github.com/huggingface/candle.git", tag = "0.9.2-alpha.2" }
candle-transformers = { git = "https://github.com/huggingface/candle.git", tag = "0.9.2-alpha.2" }
candle-flash-attn = { git = "https://github.com/huggingface/candle.git", tag = "0.9.2-alpha.2", optional = true }
safetensors = "0.7"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
tokenizers = "0.22"
thiserror = "2.0"
hf-hub = "0.4"
clap = { version = "4.0", features = ["derive"] }
image = "0.25"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
glob = "0.3"
statrs = "0.18"
gif = "0.14"
mp4 = "0.14"
rayon = "1.11.0"



[features]
default = ["flash-attn", "cudnn"]
# GPU Acceleration
flash-attn = ["dep:candle-flash-attn"]
# cuDNN for faster convolutions (requires CUDA)
cudnn = ["candle-core/cudnn"]
# Intel MKL for CPU acceleration (Linux/Windows x86_64)
mkl = ["candle-core/mkl"]
# Apple Accelerate for Metal acceleration (macOS)
accelerate = ["candle-core/accelerate"]
# NCCL for multi-GPU support
nccl = ["candle-core/nccl"]
# All GPU optimizations (for maximum performance)
all-gpu = ["flash-attn", "cudnn", "nccl"]

[dev-dependencies]
criterion = { version = "0.8", features = ["html_reports"] }
tempfile = "3.0"
bytemuck = "1.0"
