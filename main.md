Технический отчет: Глубокий анализ архитектуры LTX-Video и дорожная карта реализации в экосистеме Rust (Candle)

1. Введение и стратегический контекст

Современный ландшафт генеративного искусственного интеллекта переживает фундаментальный сдвиг от классических методов диффузии к архитектурам, основанным на трансформерах (Diffusion Transformers, DiT), способным обрабатывать мультимодальные данные с высокой степенью согласованности. В этом контексте модель LTX-Video, представленная компанией Lightricks, выделяется как новаторское решение, объединяющее высокую эффективность сжатия и генеративную мощь в едином "холистическом" конвейере. Данный отчет представляет собой исчерпывающий технический анализ архитектуры LTX-Video и детальную стратегию её переноса в среду языка Rust с использованием фреймворка Candle от Hugging Face.

Выбор Rust в качестве целевой платформы для инференса видео-моделей не случаен. В то время как Python остается стандартом де-факто для исследований и обучения, его ограничения — в частности, Global Interpreter Lock (GIL), высокое потребление памяти и зависимость от тяжеловесного runtime — создают существенные барьеры для высокопроизводительного, масштабируемого развертывания в production-средах (Edge computing, serverless). Фреймворк Candle, предлагающий абстракции с нулевой стоимостью (zero-cost abstractions) и управление памятью без сборщика мусора, представляет собой перспективную альтернативу, позволяющую достичь производительности, сопоставимой с нативными C++ решениями, при сохранении эргономики высокоуровневого языка.

Однако, как показывает предварительный анализ, экосистема Candle, будучи зрелой для задач обработки естественного языка (LLM), сталкивается с рядом специфических вызовов при работе с 5-мерными тензорами (видео) и нестандартными механизмами позиционирования, применяемыми в LTX-Video. Цель данного документа — не просто описать архитектуру, но и предоставить инженерное руководство по преодолению этих разрывов (gap analysis), предлагая конкретные математические и программные решения для реализации LTX-Video на Rust.

2. Архитектурная деконструкция LTX-Video

Модель LTX-Video представляет собой не просто эволюцию существующих решений, а

переосмысление взаимодействия между компонентами генеративной системы. Традиционные подходы, такие как Stable Video Diffusion (SVD), рассматривают видео-VAE (вариационный автоэнкодер) и денойзер (UNet или DiT) как независимые модули. LTX-Video же оптимизирует их совместную работу, что критически важно для достижения заявленной скорости генерации — быстрее реального времени на GPU класса H100.¹

## 2.1. Концепция "Холистической" генерации

Ключевым отличием LTX-Video является интеграция задач. Вместо того чтобы просто сжимать данные, VAE берет на себя часть функций шумоподавления, особенно на финальных этапах восстановления высокочастотных деталей. Это позволяет разгрузить основной трансформер, позволяя ему оперировать в экстремально сжатом латентном пространстве, не теряя при этом визуальной четкости.²

Для инженера, реализующего эту систему на Rust, это означает, что архитектура инференс-пайплайна должна быть более гибкой, чем линейная последовательность Encode -&gt; Denoise -&gt; Decode. Необходимо предусмотреть передачу условий (conditioning), таких как временной шаг диффузии, непосредственно в декодер VAE, что требует поддержки динамических графов вычислений или специфической реализации модуля декодера.

## 2.2. Causal Video-VAE: Двигатель эффективности

Эффективность LTX-Video базируется на беспрецедентном коэффициенте сжатия 1:192. Для сравнения, стандартные VAE в моделях Stable Diffusion обеспечивают сжатие 1:8. Такое агрессивное уменьшение размерности достигается за счет пространственно-временного даунсемплинга: пространство сжимается в 32 раза ($32 \times 32$), а время — в 8 раз.²

## 2.2.1. Пространственно-временная патчификация

В классических Vision Transformers (ViT) операция разбиения изображения на патчи (patchify) происходит на входе в трансформер. В LTX-Video эта операция перенесена на вход VAE. Это означает, что VAE принимает сырье пиксели и сразу формирует то, что можно назвать "супер-токенами".

- Техническое следствие: Входной тензор для VAE имеет размерность $(B, C, T, H, W)$, где $C=3$ (RGB). Выходной латентный тензор имеет размерность $(B, C_(lat), T/8, H/32, W/32)$, где $C_(lat)=128$.³ Увеличенная глубина каналов (128 против стандартных 4 или 16) компенсирует потерю пространственного разрешения, сохраняя семантическую информацию.

## 2.2.2. Причинность (Causality) и 3D Свертки

Термин "Causal" в названии VAE указывает на то, что модель не "заглядывает в будущее"

при обработке временной последовательности. Это достигается использованием причинных 3D-сверток (Causal Conv3D).

- Математика причинности: В стандартной свертке паддинг (дополнение нулями) добавляется симметрично с обеих сторон оси времени. В причинной свертке паддинг добавляется только перед текущим кадром. Если ядро свертки по времени имеет размер $K_t$, то необходимо добавить $K_t - 1$ нулевых кадров в начало последовательности (или использовать маскирование), чтобы выход в момент $t$ зависел только от входов $t, t-1, \dots, t-K_t+1$.

- Имплементация: Это создает серьезный вызов для Candle, так как стандартные примитивы сверток часто не поддерживают асимметричный паддинг "из коробки" или требуют ручной манипуляции тензорами перед вызовом операции свертки.

|  Характеристика | Стандартный Video VAE | LTX Causal Video VAE | Импликации для Candle  |
| --- | --- | --- | --- |
|  Сжатие | 1:8 (пространственно e), часто без временного | 1:192 (32x32x8) | Требует высокой точности (BF16/FP32), FP16 может давать NaN.  |
|  Тип сверток | 2D (покадрово) или "Pseudo-3D" | Causal 3D Conv | Необходима реализация Conv3d с кастомным паддингом.  |
|  Декодер | Реконструкция | Реконструкция + Denoising | Декодер требует timestep как входной аргумент.  |

## 2.3. DiT Backbone: Модифицированный PixArt-\$\alpha\$

В качестве "мозга" генерации LTX-Video использует архитектуру Diffusion Transformer, основанную на PixArt-\$\alpha\$, но адаптированную для обработки 3D-данных.⁴

## 2.3.1. Full Spatiotemporal Attention

Из-за экстремального сжатия латентного пространства, LTX-Video может позволить себе использовать полное внимание (Full Self-Attention), где каждый токен видео взаимодействует с каждым другим токеном в пространстве и времени. Это отличается от факторизованного внимания (раздельное пространственное и временное),

используемого в моделях типа Sora или CogVideoX для экономии памяти.

- Влияние на производительность: Полное внимание квадратично зависит от длины последовательности $L = T_{lat} \times H_{lat} \times W_{lat}$. Однако, благодаря сжатию 1:192, $L$ остается в разумных пределах даже для длинных видео. Тем не менее, использование Flash Attention 2 становится обязательным требованием для реализации на Rust.

## 2.3.2. Normalized Fractional RoPE

Одним из самых инновационных и сложных для реализации компонентов является система позиционного кодирования. Стандартный Rotary Positional Embedding (RoPE) оперирует целочисленными индексами. LTX-Video вводит нормализованные дробные координаты.³

- Проблема: При генерации видео с разным разрешением и FPS абсолютные позиции токенов могут сильно варьироваться, выходя за пределы распределения, на котором обучалась модель.
- Решение: Координаты нормализуются. Например, временная координата $t$ преобразуется в $t' \in S$ относительно максимальной длительности видео. Аналогично для пространственных координат.
- Вызов: Библиотеки глубокого обучения, включая candle-nn, обычно генерируют частоты RoPE на основе arange(seq_len). Для LTX потребуется написать кастомный генератор частот, принимающий тензоры дробных координат.

## 2.4. Rectified Flow Scheduler

Вместо классической DDPM диффузии используется формулировка Rectified Flow (RF).⁵ Математически это означает, что модель учится предсказывать поле скоростей $v(x, t)$, перемещающее точки данных по прямым траекториям от шумового распределения к целевому.

- Инференс: Это позволяет использовать простейший решатель ОДУ — метод Эйлера первого порядка.

$$
\$ \text{x}_{\text{t-1}} = \text{x}_t - \text{\Delta t} \cdot \text{cdot} \, v_{\text{theta}}(x_t, t) \quad \$
$$

Это существенно упрощает реализацию планировщика (Scheduler) в Candle по сравнению с многоступенчатыми алгоритмами типа PNDM или DPMSolver++.

## 3. Технический аудит фреймворка Candle

Фреймворк Candle позиционируется как минималистичное, но мощное решение для ML на Rust. Его ключевые преимущества включают отсутствие Python-зависимостей, возможность компиляции в бинарный файл, поддержку WebAssembly (WASM) и эффективную работу с GPU через cudarc и candle-kernels.⁷ Однако анализ применимости

к LTX-Video выявляет ряд критических ограничений.

## 3.1. Анализ поддержки тензорных операций

Candle предоставляет структуру Tensor, которая является оберткой над Storage (CPU, CUDA, Metal). Она поддерживает N-мерные тензоры, что теоретически позволяет работать с 5D-видео $(B, C, T, H, W)$.⁹

- Поддерживается:
- Базовые операции (add, sub, mul, div).
- Матричные умножения (matmul, broadcast_matmul).
- Изменения формы (reshape, permute, transpose, view).
- Загрузка весов через safetensors (нативная поддержка, zero-copy).
- Flash Attention v2 (через интеграцию flash-attn kernel).

## 3.2. Gap Analysis: Проблема отсутствия Conv3D

Наиболее существенным препятствием является отсутствие высокоуровневой реализации 3D-сверток (Conv3d) и 3D-пулинга (MaxPool3d, AvgPool3d) в крейте candle-nn.¹¹

- Текущий статус: Сообщество неоднократно запрашивало поддержку 3D-операций для медицинских задач и видео, но на момент написания отчета официальной реализации в candle-core нет. В Issue #795 на GitHub разработчики предлагают либо использовать workaround через 2D-свертки, либо писать кастомные опкоды (Custom Ops).¹¹
- Влияние на LTX: VAE в LTX-Video целиком построен на 3D-свертках. Без эффективной реализации этого слоя инференс модели невозможен или будет катастрофически медленным.

## 3.3. Анализ поддержки квантования и памяти

LTX-Video — массивная модель (13В параметров для основной версии, плюс VAE и T5). Управление памятью критично.

- Quantization: Candle имеет мощную поддержку квантования GGUF (через candle-quantized), что позволяет запускать большие языковые модели на CPU и потребительских GPU. Это применимо и к трансформеру LTX.
- BF16: Поддержка BFloat16 реализована на уровне CUDA-ядер, что является оптимальным форматом для инференса на современных GPU (Ampere и новее), так как обеспечивает тот же динамический диапазон, что и FP32, при половинном потреблении памяти.¹²

## 4. Дорожная карта реализации: Фаза 1 — Фундамент

Первая фаза реализации фокусируется на подготовке инфраструктуры проекта и

обеспечении корректной загрузки данных.

## 4.1. Структура проекта и зависимости

Проект на Rust должен быть организован как библиотека с исполняемым бинарным файлом. В Cargo.toml необходимо включить следующие зависимости:

```
Ini, TOML

[dependencies]
candle-core = { version = "0.9", features = ["cuda", "flash-attn", "cudnn"] }
candle-nn = "0.9"
candle-transformers = "0.9"
safetensors = "0.4"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
tokenizers = "0.19"
```

Примечание: Feature cudnn в candle-core может быть критична для ускорения сверток, если удастся задействовать вызовы cuDNN API, хотя стандартный conv2d в Candle часто использует собственные ядра.

## 4.2. Парсинг конфигурации и загрузка весов

LTX-Video использует сложные конфигурационные файлы config.json для VAE, DiT и Scheduler.¹³ Необходимо создать Rust-структуры, точно отражающие эту иерархию.

```
Rust

#
pub struct VaeConfig {
pub in_channels: usize,
pub out_channels: usize,
pub latent_channels: usize, // Обычно 128 для LTX
pub block_out_channels: Vec<usize>,
pub layers_per_block: usize,
// Специфичные параметры для causal padding
}</usize>

}

```shell
#
pub struct DitConfig {
pub patch_size: usize,
pub in_channels: usize,
pub hidden_size: usize,
pub depth: usize,
pub num_heads: usize,
pub caption_channels: usize, // 4096 для T5-XXL
}
```

Стратегия загрузки:
Используйте candle_nn::VarBuilder::from_safetensors. Поскольку веса модели LTX распространяются в формате .safetensors (часто разбитые на шарды), VarBuilder обеспечит эффективное маппирование файлов в память. Важно реализовать логику переименования (renaming logic), так как имена переменных в Python-коде (например, model.diffusion_model...) могут не совпадать с иерархией структур в Rust.

# 5. Дорожная карта реализации: Фаза 2 — Инженерный вызов VAE (Conv3D)

Это самый сложный этап, требующий реализации отсутствующих примитивов. Мы рассмотрим два подхода: эмуляция через 2D (Folding) и реализация через Custom Op.

# 5.1. Стратегия A: "Time-Folding" (Эмуляция 3D через 2D)

Если ядра свертки факторизованы (то есть $3\times3$ свертка аппроксимируется последовательностью $1\times3$ и $3\times1$), этот метод наиболее эффективен и прост в реализации на чистом Rust/Candle.

Таблица трансформаций для пространственной свертки ($1 \times K_h \times K_w$):

|  Шаг | Операция | Размерность тензора | Пояснение  |
| --- | --- | --- | --- |
|  1 | Вход | $(B, C, T, H, W)$ | Исходный 5D тензор  |
|  2 | Permute/Reshape | $(B \times T, C, H, W)$ | Объединяем Batch и Time в одну  |

Таблица трансформаций для временной свертки ($K_t \times 1 \times 1$):

|  Шаг | Операция | Размерность тензора | Пояснение  |
| --- | --- | --- | --- |
|  1 | Вход | $(B, C, T, H, W)$ | Исходный 5D тензор  |
|  2 | Permute | $(B, H, W, C, T)$ | Перемещаем T в конец (как ширину для 1D свертки)  |
|  3 | Reshape | $(B \times H \times W, C, T)$ | Объединяем пространственные оси в Batch  |
|  4 | Conv1D | $(B \times H \times W, C', T')$ | Применяем 1D свертку по времени  |
|  5 | Reshape/Permute | $(B, C', T', H, W)$ | Восстанавливаем форму  |

Анализ производительности:

Операции permute и reshape в Candle могут быть "бесплатными" (zero-copy), если они меняют только Layout (шаги/strides), но часто требуют contiguous(), что вызывает копирование памяти. Для видео высокого разрешения это может стать бутылочным горлышком.

## 5.2. Стратегия Б: Нативная реализация Conv3D (Custom Op)

Если VAE использует нефакторизованные свертки $3\times$ (что подтверждается источниками как более качественный вариант для LTX³), эмуляция через 2D будет крайне неэффективной из-за необходимости сложных сдвигов памяти. В этом случае необходимо реализовать CustomOp1 в Candle.

## Алгоритм реализации:

1. CUDA Kernel: Написать ядро на CUDA C++, реализующее прямую свертку 3D (или использовать вызовы cuDNN cudnnConvolutionForward).
2. FFI Binding: Использовать крейт bindgen или ручные объявления extern "C" для вызова ядра из Rust.
3. Candle Integration: Реализовать трейт candle_core::CustomOp1 для структуры Conv3dOp.

```rust
Rust
struct Conv3dOp {
kernel: Tensor,
stride: Vec<usize>,
padding: Vec<usize>,
dilation: Vec<usize>,
}

impl CustomOp1 for Conv3dOp {
fn name(&amp;self) -&gt; &amp;static str { "conv3d" }
fn cpu_fwd(&amp;self, s: &amp;CpuStorage, l: &amp;Layout) -&gt; Result<cpustorage, shape=""> {
// Реализация для CPU (медленная, через циклы или im2col)
todo!("CPU conv3d not efficient")
}
fn cuda_fwd(&amp;self, s: &amp;CudaStorage, l: &amp;Layout) -&gt; Result<cuda storage,="" shape=""> {
// Вызов CUDA ядра
run_conv3d_kernel(...)
}
}
```

4. Causal Padding: Реализовать функцию паддинга, которая добавляет нули только слева по оси $T$.

```rust
Rust
fn causal_pad(x: &amp;Tensor, pad: usize) -&gt; Result<tensor> {
// x shape: (B, C, T, H, W)
}</tensor></cuda></usize></usize></usize>

// Pad dim 2 (Time) with (pad, 0) -&gt; (left, right)
x.pad_with_zeros(2, pad, 0)
}

# 6. Дорожная карта реализации: Фаза 3 — Трансформер и Внимание

Реализация DiT требует решения двух нестандартных задач: выпрямления 3D-пространства и дробного позиционирования.

## 6.1. Линеаризация токенов (Unpatchify workaround)

Трансформеры работают с последовательностями. 5D-латент от VAE необходимо превратить в 3D-тензор $(B, L, D)$.

- Логика: Поскольку VAE LTX уже выполнил "патчификацию"², трансформеру не нужно нарезать патчи. Нужно лишь объединить оси $T, H, W$.
- let input_seq = latents.permute((0, 2, 3, 4, 1))?.flatten_from(1)?.flatten_from(1)?;
- Результат: $(B, T \cdot H \cdot W, C)$.

## 6.2. Реализация Normalized Fractional RoPE

Это критический компонент для качества генерации. Стандартная реализация RoPE в candle-nn предполагает, что позиции — это индексы $0, 1, 2 \dots N$. В LTX позиции — это нормализованные float значения.

**Математическая модель:**

Пусть $t, h, w$ — абсолютные координаты токена.

Нормализованные координаты: $\hat{t} = t / T_{\max}$, $\hat{h} = h / H_{\max}$, $\hat{w} = w / W_{\max}$.

Вращение применяется к подпространствам вектора $x$. Частоты $\Theta$ зависят от этих $\hat{t}$, $\hat{h}$, $\hat{w}$.

**Реализация в Rust:**

1. Генерация сетки координат: Использовать Tensor::arange и Tensor::meshgrid (или broadcasting) для создания тензоров координат, совпадающих по форме с входной последовательностью.

2. Вычисление частот:

```text
Rust
// Псевдокод вычисления частот для Fractional RoPE
fn compute_freqs(coords: &amp;Tensor, dim: usize) -&gt; Result<tensor> {
// coords: [L], значения в
// base frequency calculation adapted for fractional inputs
let freqs =...; // exponential spacing as per LTX paper
}</tensor>

Ok(freqs)

3. Применение: Написать функцию apply_rotary_emb_3d, которая разделяет каналы (channels) головы внимания на три части (для времени, высоты, ширины) и применяет соответствующие вращения.

## 6.3. Интеграция Flash Attention 2

Для обеспечения производительности необходимо использовать Flash Attention. Candle поддерживает его через feature flash-attn.

- Важно: Flash Attention требует, чтобы размерность head dimension была кратна определенным значениям (например, 64 или 128) и тип данных был f16 или bf16. При проектировании Config структур нужно убедиться, что параметры модели соответствуют этим ограничениям.

## 7. Дорожная карта реализации: Фаза 4 — Кондиционирование и Семплинг

### 7.1. Текстовый Энкодер (T5)

LTX-Video использует T5-XXL. Это огромная модель (миллиарды параметров), которая может не поместиться в GPU вместе с DiT.

- Стратегия: Использовать CPU Offloading. Загрузить T5 в системную память, выполнить энкодинг промпта один раз в начале генерации, получить эмбеддинги, выгрузить T5 (или оставить в RAM) и перенести эмбеддинги на GPU.
- Квантование: Использовать квантованную версию T5 (например, q8_0 GGUF) через candle-quantized. Это снизит потребление памяти с ~22 ГБ (FP32) до ~5 ГБ.

### 7.2. Планировщик Rectified Flow

Реализация планировщика RF значительно проще, чем диффузионного.

Rust

```text
pub struct RectifiedFlowScheduler {
num_steps: usize,
}
```

```text
impl RectifiedFlowScheduler {

```php
pub fn step(&amp;self, model_output: &amp;Tensor, prev_sample: &amp;Tensor, dt: f64) -&gt; Result<tensor> {
// Euler step: x_{t-1} = x_t - dt * v_pred
// model_output интерпретируется как velocity (v)
let delta = (model_output * dt)?;
prev_sample.sub(&amp;delta)
}
}
```

Нюанс Guidance: В LTX используется guidance scale ($w$). Скорость корректируется: $$\hat{v} = v_{\text{und}} + w \cdot \text{odot} (v_{\text{cond}} - v_{\text{und}})$$.

Это требует двух прогонов модели (или одного с удвоенным батчем) на каждом шаге. Для видео-инференса удвоение батча может вызвать OOM (Out Of Memory), поэтому предпочтительнее делать два последовательных прогона.

# 8. Оптимизация производительности и развертывание

## 8.1. Управление памятью (Memory Management)

Видео-тензоры огромны. Тензор латентов $1 \times 128 \times 16 \times 24 \times 40$ (примерно 5 сек видео 768x1280) в BF16 занимает $\approx 400$ МБ. Однако промежуточные активации в Attention слоях могут занимать гигабайты.

- **Gradient Checkpointing**: В Candle нет встроенного автоматического gradient checkpointing для инференса (это техника обучения), но для инференса важно вовремя освобождать тензоры. Rust (RAIL) делает это автоматически, когда переменная выходит из области видимости. Важно не хранить ссылки на промежуточные тензоры дольше, чем нужно.

## 8.2. Компиляция и Типы Данных

- **BF16**: Использовать DType::BF16 везде, где возможно. Это стандарт для DiT моделей.
- **Release Build**: Сборка cargo build --release обязательна. Debug версия может быть в 10-100 раз медленнее из-за проверок границ массивов и отсутствия векторизации.

# 9. Заключение

Реализация LTX-Video на Rust с использованием Candle — амбициозная инженерная задача, лежащая на переднем крае возможностей open-source ML. Основной барьер — отсутствие нативных 3D-операций в Candle — преодолим либо через математически эквивалентные трансформации тензоров (Folding), либо через интеграцию кастомных CUDA-ядер. Второй подход предпочтителен для достижения заявленной производительности "быстрее реального времени".

Успешная реализация данного проекта не только позволит запустить SOTA</tensor>

видео-генератор в высокопроизводительной среде без Python, но и создаст прецедент для использования Rust в задачах 3D-компьютерного зрения и генерации видео, расширяя границы применимости фреймворка Candle.

## Сводная таблица ключевых этапов реализации

|  Этап | Задача | Ключевая сложность | Решение  |
| --- | --- | --- | --- |
|  1. Фундамент | Конфиг, Safetensors | Различия в именовании весов | Mapping-слой в VarBuilder  |
|  2. VAE | Causal Conv3D | Отсутствие в Candle | 2D Folding (MVP) или Custom CUDA Op (Prod)  |
|  3. DiT | Fractional RoPE | Нестандартная математика | Кастомный генератор частот + arange  |
|  4. DiT | Spatiotemporal Attn | Память и скорость | Flash Attention v2 + BF16  |
|  5. Pipeline | T5 Integration | Размер модели | CPU Offloading + Quantization (GGUF)  |
|  6. Scheduler | Rectified Flow | Простота | Euler Solver + CFG Logic  |

Этот отчет служит детальной инструкцией для ML-инженеров, готовых приступить к кодированию архитектуры LTX-Video на Rust.

## Works cited

1. Lightricks/LTX-Video: Official repository for LTX-Video - GitHub, accessed December 22, 2025, https://github.com/Lightricks/LTX-Video
2. Paper page - LTX-Video: Realtime Video Latent Diffusion - Hugging Face, accessed December 22, 2025, https://huggingface.co/papers/2501.00103
3. LTX-Video: Realtime Video Latent Diffusion - arXiv, accessed December 22, 2025, https://arxiv.org/html/2501.00103v1

4. xdiffusion/docs/video/ltx_video.md at main - GitHub, accessed December 22, 2025, https://github.com/swookey-thinky/xdiffusion/blob/main/docs/video/ltx_video.md
5. DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized: Advanced LTX Video generation with intelligent ZeroGPU configuration - GitHub, accessed December 22, 2025, https://github.com/DeepRatAI/LTX-FastVideo-ZeroGPU_Optimized
6. rectified-flow - PyPI, accessed December 22, 2025, https://pypi.org/project/rectified-flow/
7. Introduction - Candle Documentation, accessed December 22, 2025, https://huggingface.github.io/candle/
8. Candle - Candle by Hugging Face: a minimalist, high-performance ML framework in Rust ... - Jimmy Song, accessed December 22, 2025, https://jimmysong.io/ai/candle/
9. Tensor in candle_core - Rust - Docs.rs, accessed December 22, 2025, https://docs.rs/candle-core/latest/candle_core/struct.Tensor.html
10. candle_core/ tensor.rs, accessed December 22, 2025, https://docs.rs/candle-core/latest/src/candle_core/tensor.rs.html
11. Support Conv3D · Issue #795 · huggingface/candle - GitHub, accessed December 22, 2025, https://github.com/huggingface/candle/issues/795
12. diffusers/docs/source/en/api/pipelines/ltx_video.md at main - GitHub, accessed December 22, 2025, https://github.com/huggingface/diffusers/blob/main/docs/source/en/api/pipelines/ltx_video.md
13. openvino_notebooks/notebooks/ltx-video/ltx-video.ipynb at latest - GitHub, accessed December 22, 2025, https://github.com/openvinotoolkit/openvino_notebooks/blob/latest/notebooks/ltx-video/ltx-video.ipynb
14. Upload 35 files · Lightricks/ltx-video-distilled at 833590f - Hugging Face, accessed December 22, 2025, https://huggingface.co/spaces/Lightricks/ltx-video-distilled/commit/833590f8f4211f102156c68f35d81f35baf62a81

